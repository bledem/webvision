{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Extract bottleneck features using neural network. \"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import torch\n",
    "import pickle as cPickle\n",
    "from os.path import join as pjoin\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from cnn.factory import get_model\n",
    "from cnn.config import cfg\n",
    "from datasets.folder import SpecImageFolder\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/mnt/data1/webvision2.0\"\n",
    "batch_size = 100 \n",
    "input_size= 224\n",
    "arch=\"resnet50\"\n",
    "gpus =\"0,1,2,3\" \n",
    "data_folder =\"both\" \n",
    "save_freq = 5000\n",
    "num_classes= 5607 #number of class we want\n",
    "print_freq= 10000\n",
    "load_path ='/home/betty/webvision_train/results/resnet50/5000classes_onemonth/'\n",
    "num_workers = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "images_so_far = 0\n",
    "save_path='/home/betty/webvision_train/results/resnet50/training_features'\n",
    "params_file=\"/home/betty/webvision_train/results/resnet50/5000classes_onemonth/model_best.tar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries=[]\n",
    "previous=-1\n",
    "all=True #to activate if you want all the query put in one class\n",
    "if (num_classes is None):\n",
    "    all=True\n",
    "with open(os.path.join(data_path, 'info', 'queries_synsets_map.txt')) as f:\n",
    "        for line in f:\n",
    "            # Image path\n",
    "            if((line.split()[1] != previous) or all):\n",
    "                queries.append(int(line.split()[0]))\n",
    "                previous=line.split()[1]\n",
    "                #print(line.split()[0], \" \", line.split()[1])\n",
    "            elif ((len(queries)>=query) and not all):\n",
    "                print(\"over the class\", query, 'queries is', queries)\n",
    "                break\n",
    "query_synset_dic = {}\n",
    "with open(\"/home/betty/Pictures/webvision/info/queries_synsets_map.txt\") as f:\n",
    "    for line in f:\n",
    "       (key, val) = line.split()\n",
    "       if (int(val)<=int(num_classes)):\n",
    "           query_synset_dic[int(key)] = val\n",
    "#print(\"We use \", query_synset_dic, \"queries as synset map\")\n",
    "# print(\"class weighted\", args.class_weighted )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_to_pickle(features, save_path, cls_id, fname):\n",
    "\n",
    "    with open(pjoin(save_path, cls_id, fname + \".pkl\"), 'wb') as f:\n",
    "        cPickle.dump(features, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def save_to_txt(img_tuple, save_path, cls_id):\n",
    "    with open(pjoin(save_path, cls_id, \"img_name.lst\"), 'w') as f:\n",
    "        for img_path, _ in img_tuple:\n",
    "            f.write(img_path + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_feats(ext_loader, folder, model,\n",
    "                  save_path, cls_id,\n",
    "                  save_freq=200):\n",
    "    # switch to evaluate mode\n",
    "    save_path = pjoin(save_path, folder)\n",
    "    model.eval()\n",
    "    print(pjoin(save_path, cls_id))\n",
    "    if not os.path.exists(pjoin(save_path, cls_id)): #save the resulting feature\n",
    "        os.mkdir(pjoin(save_path, cls_id))\n",
    "\n",
    "    batch_feat = []\n",
    "    img_names = ext_loader.dataset.imgs\n",
    "    batch_size = ext_loader.batch_size\n",
    "    num_img = len(img_names)\n",
    "    init_idx = 0\n",
    "    pkl_idx = 0\n",
    "    last_idx = int(math.ceil(num_img / float(batch_size))) - 1\n",
    "\n",
    "    for idx, data in enumerate(ext_loader, 0):\n",
    "        inputs, _ = data\n",
    "        inputs = Variable(inputs.to(device))\n",
    "        feats = model(inputs)\n",
    "        print(\"check shape\", feats.shape)\n",
    "\n",
    "        cpu_feat = feats.data.cpu().numpy()\n",
    "        if len(cpu_feat.shape) == 1:\n",
    "            cpu_feat = np.reshape(cpu_feat, (1, -1))\n",
    "        batch_feat.append(cpu_feat)\n",
    "\n",
    "        if idx % save_freq == (save_freq - 1):\n",
    "            # batch_im_list = img_names[\n",
    "            #     init_idx: batch_size * save_freq + init_idx]\n",
    "            # init_idx = batch_size * save_freq + init_idx\n",
    "            batch_feat = np.concatenate(batch_feat, axis=0)\n",
    "            save_to_pickle(batch_feat, save_path, cls_id, str(pkl_idx))\n",
    "\n",
    "            batch_feat = []\n",
    "            pkl_idx += 1\n",
    "\n",
    "        elif idx == last_idx:\n",
    "            # batch_im_list = img_names[init_idx:]\n",
    "            batch_feat = np.concatenate(batch_feat, axis=0)\n",
    "\n",
    "            save_to_pickle(batch_feat, save_path, cls_id, str(pkl_idx))\n",
    "\n",
    "    # save to text\n",
    "    save_to_txt(img_names, save_path, cls_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_model(data_root, gpus=gpus, batch_size=16,\n",
    "                  params_file=\"/home/betty/webvision_train/results/resnet50/5000classes_onemonth/model_best.tar\",\n",
    "                  num_workers=4, num_classes=5000,\n",
    "                  in_size=224, save_path=None, dict_=None):\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    ext_transform = transforms.Compose([\n",
    "        transforms.Resize((in_size, in_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize])\n",
    "    print(params_file)\n",
    "    assert os.path.isfile(params_file), \"{} is not exist.\".format(params_file)\n",
    "    # define the model\n",
    "    model = get_model(name=arch,\n",
    "                      num_classes=num_classes, extract_feat=True)\n",
    "    if len(gpus) > 1:\n",
    "        prev_gpus = gpus\n",
    "        gpus = [int(i) for i in gpus.strip('[]').split(',')]\n",
    "        print(\"Let's use\", gpus, \"on\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] =  prev_gpus #we give this number as the device id we use\n",
    "        gpus_idx = range(0,len(gpus))\n",
    "        model = torch.nn.DataParallel(model, device_ids=gpus_idx)\n",
    "    elif len(gpus) == 1:\n",
    "        prev_gpus = gpus\n",
    "        gpus = [int(i) for i in gpus.strip('[]').split(',')]\n",
    "        print(\"Let's use\", gpus, \"on\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] =  prev_gpus #we give this number as the device id we use\n",
    "\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpus\n",
    "        print(\"no gpus\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.cuda()\n",
    "    params = torch.load(params_file)\n",
    "\n",
    "    model.load_state_dict(params['state_dict'])\n",
    "    #modules = list(model.children())[:-1]\n",
    "    #model =  nn.Sequential(*modules)\n",
    "    \n",
    "    ##un comment to PRINT the model\n",
    "#     print(\"Params to learn:\")\n",
    "#     feature_extract=False\n",
    "#     if feature_extract:\n",
    "#         params_to_update = []\n",
    "#         for name,param in model.named_parameters():\n",
    "#             if param.requires_grad == True:\n",
    "#                 params_to_update.append(param)\n",
    "#                 print(\"\\t\",name)\n",
    "#     else:\n",
    "#         for name,param in model.named_parameters():\n",
    "#             if param.requires_grad == True:\n",
    "#                 print(\"\\t\",name)\n",
    "    feature_map = list(model.module.children())\n",
    "    feature_map.pop()\n",
    "    extractor = nn.Sequential(*feature_map)\n",
    "    extractor.to(device)\n",
    "    extractor.cuda()\n",
    "    #print(\"feature_map\", feature_map)\n",
    "    for name,param in extractor.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "    \n",
    "#for every query\n",
    "    for cls_id in sorted(os.listdir(data_root)): #args.data_path  \n",
    "        print(\"Processing class {}\".format(cls_id))\n",
    "        ext_data = SpecImageFolder(root=pjoin(data_root, cls_id),\n",
    "                                   transform=ext_transform, dict_=dict_)\n",
    "        ext_loader = DataLoader(dataset=ext_data, batch_size=batch_size,\n",
    "                                shuffle=False, num_workers=num_workers,\n",
    "                                pin_memory=True)\n",
    "        extract_feats(ext_loader, data_root[24:30], extractor, save_path,  cls_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "google_path=\"/mnt/data1/webvision2.0/google_images_resized\"\n",
    "flickr_path=\"/mnt/data1/webvision2.0/flickr_images_resized\"\n",
    "extract_model(google_path,\n",
    "                  gpus,\n",
    "                  batch_size,\n",
    "                  params_file,\n",
    "                  num_workers,\n",
    "                  num_classes,\n",
    "                  input_size,\n",
    "                  save_path,dict_=query_synset_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
