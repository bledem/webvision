{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from os.path import join as pjoin\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from datasets.folder import GenImageFolder, SpecImageFolder, DriveData, SampleData\n",
    "from cnn.utils import adjust_lr, save_ckpt, adjust_lr_manual, plot_confusion_matrix, accuracy, AverageMeter, name_of_class\n",
    "from cnn import utils\n",
    "from cnn.factory import get_model\n",
    "from cnn.config import cfg\n",
    "from cnn.logger import Logger\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"/mnt/data1/webvision2.0\"\n",
    "batch_size = 256 \n",
    "arch = 'resnet50'\n",
    "input_size= 224\n",
    "gpus =\"3\" \n",
    "lr= 0.1\n",
    "data_folder =\"both\" \n",
    "save_freq = 5000\n",
    "print_freq= 10000\n",
    "epochs= 500\n",
    "query= 5607 #number of class we want\n",
    "class_weighted= 0 \n",
    "load_path ='/home/betty/webvision_train/results/resnet50/5000classes_onemonth/'\n",
    "weight_decay=1e-4\n",
    "num_workers = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "images_so_far = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(train_loader, model, print_freq):\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    model.eval()\n",
    "    num_correct = 0.\n",
    "    num_samples = 0.\n",
    "    classes_names, synset_name = name_of_class()\n",
    "\n",
    "    for idx, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    " \n",
    "        # feedforward\n",
    "        output = model(inputs)\n",
    "        acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "        top1.update(acc1[0], inputs.size(0))\n",
    "        top5.update(acc5[0], inputs.size(0))\n",
    "\n",
    "        _, preds = torch.max(output, 1)\n",
    "        correct = (preds == labels).sum()\n",
    "        print('Predicted: ', ' //'.join('%5s' % classes_names[preds[j]] for j in range(len(labels))))\n",
    "        print('Ground Truth is: ', ' //'.join('%5s' % classes_names[labels[j]] for j in range(len(labels))))\n",
    "        num_samples += labels.size(0)\n",
    "        num_correct += correct.item()\n",
    "\n",
    "        if idx % print_freq == (print_freq - 1):\n",
    "            running_acc = num_correct / float(num_samples)\n",
    "\n",
    "            print(   'acc: {0:.4f}' 'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t' 'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                 running_acc, \n",
    "                    top1=top1, top5=top5 ))\n",
    "\n",
    "            num_samples, num_correct = 0., 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion,\n",
    "          optimizer, epoch, log, print_freq, save_freq, model_name):\n",
    "    global images_so_far\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"[epoch: {}]\".format(epoch + 1))\n",
    "\n",
    "    running_loss, running_acc = 0., 0.\n",
    "    num_samples, num_correct = 0., 0.\n",
    "    info = []\n",
    "\n",
    "    for idx, data in enumerate(train_loader, 0):\n",
    "        data_time.update(time.time() - end)\n",
    "        inputs, labels = data\n",
    "        images_so_far += len(labels)\n",
    "\n",
    "        inputs, labels = Variable(inputs.to(device)), Variable(labels.to(device))\n",
    " \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # feedforward\n",
    "        output = model(inputs)\n",
    "        acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "        top1.update(acc1[0], inputs.size(0))\n",
    "        top5.update(acc5[0], inputs.size(0))\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        _, preds = torch.max(output, 1)\n",
    "        correct = (preds == labels).sum()\n",
    "\n",
    "        num_samples += labels.size(0)\n",
    "        num_correct += correct.item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if idx % print_freq == (print_freq - 1):\n",
    "            running_acc = num_correct / float(num_samples)\n",
    "            ave_running_loss = running_loss / print_freq\n",
    "\n",
    "            print('[epoch {0:d} ' 'nb done batches  {1:4d}\\t' 'seen:{4:d}\\t' 'loss: {2:.4f}\\t' ' acc: {3:.4f}'\n",
    "             'Batch_time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'  'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                epoch + 1, idx + 1,\n",
    "                ave_running_loss,\n",
    "                running_acc, images_so_far, batch_time=batch_time,\n",
    "                    top1=top1, top5=top5 ))\n",
    "        \n",
    "            log.record_trn([epoch + 1, idx + 1,\n",
    "                            ave_running_loss,\n",
    "                            running_acc])\n",
    "\n",
    "            num_samples, num_correct = 0., 0.\n",
    "            running_loss = 0.\n",
    "\n",
    "\n",
    "        if idx % save_freq == (save_freq - 1):\n",
    "            print(\"saving at\", idx, \"iteration\")\n",
    "            torch.save({'arch': model_name,\n",
    "                       'state_dict': model.state_dict(), #add .module because of DataParallel \n",
    "                       'epoch' : epoch,\n",
    "                       'idx' : idx,\n",
    "                       'optimizer_state_dict': optimizer.state_dict()},\n",
    "                      os.path.join('../results', model_name, 'in_between.tar'))\n",
    "            log.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_root,queries={}, query_synset_dic_={}, batch_size=64,num_workers=1,\n",
    "                in_size=224,):\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    # Image transformer\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(in_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize])\n",
    "    valid_transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(in_size),\n",
    "            transforms.ToTensor(),\n",
    "            normalize])\n",
    "\n",
    "\n",
    "    valid_data = DriveData(folder_dataset=data_root, dataset_type='val',  #val_images_resized\n",
    "                                transform=valid_transform, queries_= queries, dict_=query_synset_dic_)\n",
    "    print(\"flickr\")\n",
    "    train_data_flickr = SampleData(root=data_root, folder='flickr_images_resized', #reduced alias of google 10 webvision in Picture folder\n",
    "                                transform=train_transform, queries_= queries, dict_=query_synset_dic_)\n",
    "\n",
    "    print(\"google\")\n",
    "    train_data_google = SampleData(root=data_root, folder='google_images_resized', \n",
    "                                transform=train_transform, queries_= queries, dict_=query_synset_dic_)\n",
    "\n",
    "    print(\"Validation and training data loaded\")\n",
    "    #train_data_dummy = GenImageFolder(root=pjoin(data_root, 'val_images_resized'), #val\n",
    "    #                            transform=train_transform)\n",
    "    \n",
    "    #train_loader = DataLoader(dataset=train_data_dummy, batch_size=batch_size,\n",
    "    #                         shuffle=True, num_workers=num_workers,\n",
    "    #                        pin_memory=True) \n",
    "    if(data_folder=='google'):\n",
    "        train_loader = DataLoader(dataset=train_data_google, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=num_workers,\n",
    "                              pin_memory=True)\n",
    "        print(\"training from google, on\" , len(train_data_google))\n",
    "        class_weight_google = train_data_google.class_fq\n",
    "\n",
    "    elif (data_folder=='flickr'):\n",
    "        train_loader = DataLoader(dataset=train_data_flickr, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=num_workers,\n",
    "                              pin_memory=True)\n",
    "        print(\"training from flickr on\" , len(train_data_flickr) )\n",
    "        class_weight_flickr = train_data_flickr.class_fq\n",
    "\n",
    "    elif (data_folder=='both'):\n",
    "        concat_data = ConcatDataset((train_data_google, train_data_flickr))\n",
    "        print(\"training from both, on\" , len(train_data_google)+len(train_data_flickr) )\n",
    "        #class_weight = class_weight_google+ class_weight_flickr\n",
    "        train_loader = DataLoader(dataset= concat_data, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=num_workers,\n",
    "                              pin_memory=True)\n",
    "\n",
    "    #else:\n",
    "     \t#print(\"training from dummy, on\" , len(train_data_dummy) )\n",
    "\n",
    "\n",
    "    \n",
    "    valid_loader = DataLoader(dataset=valid_data, batch_size=4,\n",
    "                              shuffle=False, num_workers=num_workers,\n",
    "                              pin_memory=True)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(valid_loader, model, criterion, epoch, log, print_freq):\n",
    "    print(\"Start validation..\")\n",
    "    classes_names, synset_name = name_of_class()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    top1 = utils.AverageMeter()\n",
    "    top5 = utils.AverageMeter()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    num_correct = 0.\n",
    "    num_samples = 0.\n",
    "    num_batch = 0\n",
    "    v_value_loss = 0.\n",
    "    num_correct5 = 0.\n",
    "\n",
    "#for the confusion matrix\n",
    "    cm_label=[];\n",
    "    cm_pred=[];\n",
    "\n",
    "    for idx, data in enumerate(valid_loader, 0):\n",
    "        num_batch = idx + 1\n",
    "        inputs, labels = data       \n",
    "        #cm_label= labels.cpu().numpy()\n",
    "\n",
    "        inputs = Variable(inputs.to(device))\n",
    "        labels = Variable(labels.to(device))\n",
    "\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        _, preds = torch.max(output, 1)\n",
    "        ps = torch.exp(output)\n",
    "        #print('shape output', ps.shape, 'and preds', preds.shape) #shape output torch.Size([4, 5607]) and preds torch.Size([4]) for batch_size 1 on 4GPU\n",
    "        top_5_ps, top_5_classes = output.topk(5, dim=1) #top_5_ps.shape is torch.Size([4, 5]). top_5_classes first cl is the top1 pred and other column are top5\n",
    "        #print('preds debug', preds.data.cpu().numpy())\n",
    "        cm_label = np.concatenate([cm_label,labels.data.cpu().numpy()])\n",
    "        cm_pred = np.concatenate([cm_pred, preds.data.cpu().numpy().astype(int)])\n",
    "        #np.set_printoptions(suppress=True)\n",
    "        #print('cm_label', cm_label, 'cm_pred', cm_pred )\n",
    "\n",
    "        #for top5 acc\n",
    "        acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "\n",
    "        correct = (preds == labels).sum()\n",
    "        top1.update(acc1[0], inputs.size(0))\n",
    "        top5.update(acc5[0], inputs.size(0))\n",
    "        top_5_classes = top_5_classes.t()\n",
    "        correct5 =  top_5_classes.eq(labels.view(1, -1).expand_as(top_5_classes))\n",
    "        #print('details', top_5_classes , 'gtruth', labels )\n",
    "        #print('correct whole', preds, correct)\n",
    "\n",
    "        #print('correct5 whole', correct5)\n",
    "\n",
    "        correct_5 = correct5[:5].view(-1).float().sum(0, keepdim=True)\n",
    "\n",
    "        #print('num_correct5 %', num_correct5, 'and correct_5', correct_5)\n",
    "\n",
    "        #cm_pred+= preds.cpu().numpy()\n",
    "\n",
    "        num_samples += labels.size(0)\n",
    "        num_correct += correct.item()\n",
    "        num_correct5 += correct_5.item()\n",
    "        v_value_loss += loss.item()\n",
    "\n",
    "        if idx % print_freq == (print_freq - 1):\n",
    "            print( 'Acc@1 last {top1.val:.3f} (avg: {top1.avg:.3f})\\t' \n",
    "                 'Acc@5 last {top5.val:.3f} (avg: {top5.avg:.3f})\\t' \n",
    "                  .format(top1_val=top1.val/float(labels.size(0)),\n",
    "                  #top5_val=correct_5.item()/float(labels.size(0)),\n",
    "                  top1=top1, top5=top5))\n",
    "            #cnf_matrix = confusion_matrix(cm_label, cm_pred)\n",
    "            #np.set_printoptions(precision=2)\n",
    "           #ax = plot_confusion_matrix(cm_label, cm_pred, classes=classes_names,\n",
    "                      #title='Confusion matrix, without normalization')\n",
    "    #plt.savefig('/home/betty/webvision_train/results/resnet50/confusion_matrix_cls_names.png')\n",
    "            cnf_matrix = confusion_matrix(cm_label, cm_pred)\n",
    "            np.savetxt(\"/home/betty/webvision_train/results/resnet50/confusion_matrix_in_between.csv\", cnf_matrix, delimiter=\",\")\n",
    "\n",
    "\n",
    "    ave_loss = v_value_loss / num_batch\n",
    "    ave_acc = num_correct / float(num_samples)\n",
    "    ave_top5 = num_correct5 / float(num_samples)\n",
    "\n",
    "    log.record_val([epoch + 1, ave_loss, ave_acc, ave_top5], epoch)\n",
    "\n",
    "    #Confusion matrix plotting\n",
    "    #cnf_matrix = confusion_matrix(cm_label, cm_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    ax = plot_confusion_matrix(cm_label, cm_pred, classes=np.arange(5000),\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    plt.savefig('/home/betty/webvision_train/results/resnet50/confusion_matrix.png')\n",
    "    ax = plot_confusion_matrix(cm_label, cm_pred, classes=classes_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    plt.savefig('/home/betty/webvision_train/results/resnet50/confusion_matrix_cls_names.png')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('[valid {0:d}] ' 'loss: {1:.4f}\\t' 'acc: {2:.4f}\\t' 'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t' 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "             'Acc@5 {top5.val:.3f} ({top5.avg:.3f})\\t' 'acc_top5 {top5_avg:.3f}'.format(\n",
    "        epoch + 1, ave_loss, ave_acc,top1=top1, top5=top5, top5_avg=ave_top5, batch_time=time.time() - end))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(gpus, epochs, data_folder=\"dummy\",\n",
    "                batch_size=64, base_lr=0.1,\n",
    "                model_name='resnet50',\n",
    "                weight_decay=0.,\n",
    "                num_workers=1,\n",
    "                num_classes=5607, \n",
    "                print_freq=100,\n",
    "                save_freq=2000,\n",
    "                load_path='/home/betty/webvision_train/results/alexnet/first_result',\n",
    "                class_weighted_= False, valid_loader=None, train_loader=None):\n",
    "\n",
    "\n",
    "\n",
    "    # define the model\n",
    "    model = get_model(name=model_name, num_classes=num_classes)\n",
    "\n",
    "    if len(gpus) > 1:\n",
    "        prev_gpus = gpus\n",
    "        gpus = [int(i) for i in gpus.strip('[]').split(',')]\n",
    "        print(\"Let's use\", gpus, \"on\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] =  prev_gpus #we give this number as the device id we use\n",
    "        gpus_idx = range(0,len(gpus))\n",
    "        model = torch.nn.DataParallel(model, device_ids=gpus_idx)\n",
    "    elif len(gpus) == 1:\n",
    "        prev_gpus = gpus\n",
    "        gpus = [int(i) for i in gpus.strip('[]').split(',')]\n",
    "        print(\"Let's use\", gpus, \"on\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] =  prev_gpus #we give this number as the device id we use\n",
    "\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpus\n",
    "        print(\"no gpus\")\n",
    "\n",
    "    model.to(device)\n",
    "    feature_extract = False\n",
    "    params_to_update = model.parameters()\n",
    "\n",
    "    ##un comment to PRINT the model\n",
    "    #print(\"Params to learn:\")\n",
    "    # if feature_extract:\n",
    "    #     params_to_update = []\n",
    "    #     for name,param in model.named_parameters():\n",
    "    #         if param.requires_grad == True:\n",
    "    #             params_to_update.append(param)\n",
    "    #             print(\"\\t\",name)\n",
    "    # else:\n",
    "    #     for name,param in model.named_parameters():\n",
    "    #         if param.requires_grad == True:\n",
    "    #             print(\"\\t\",name)\n",
    "\n",
    "\n",
    "    # define optimizer and loss function\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=base_lr,\n",
    "                                weight_decay=weight_decay,\n",
    "                                momentum=0.9)\n",
    "    if (class_weighted_):\n",
    "        print(\"use class weighted strategy\")\n",
    "        loss_func = torch.nn.CrossEntropyLoss(class_weight).to(device)\n",
    "    else:\n",
    "        loss_func = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # define logs\n",
    "    logger = Logger(arch=model_name, epochs=epochs,\n",
    "                    batch_size=batch_size)\n",
    "    # create model results folder\n",
    "    res_save_fld = os.path.join('../results', model_name)\n",
    "    if not os.path.exists(res_save_fld):\n",
    "        os.mkdir(res_save_fld)\n",
    "    log_save_path = os.path.join('../logs', model_name)\n",
    "    if not os.path.exists(log_save_path):\n",
    "        os.mkdir(log_save_path)\n",
    "\n",
    "    #lr_epoch_map = {0: 0.01, 20: 0.001, 60: 0.0001}\n",
    "    if (os.path.exists(load_path)):\n",
    "        checkpoint = torch.load(os.path.join(load_path, \"one_gpu_best.tar\"))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"Successfully load the saved model at\",os.path.join(load_path, \"one_gpu_best.tar\") )\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "    \t#loss_saved = checkpoint['loss']\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \t\n",
    "        #if (epoch==1 and (os.path.exists(load_path))):\n",
    "            #epoch = checkpoint['epoch']\n",
    "            #loss_saved = checkpoint['loss']\n",
    "    \t#adjust_lr_manual(optimizer, epoch, lr_epoch_map)\n",
    "        adjust_lr(optimizer, epoch, base_lr)\n",
    "        # train for one epoch\n",
    "        validate(valid_loader, model, loss_func, epoch, logger, print_freq)\n",
    "\n",
    "        test(valid_loader, model, print_freq)\n",
    "\n",
    "        train(train_loader, model, loss_func, optimizer,\n",
    "              epoch, logger, print_freq, save_freq, model_name)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\t\t# Returns the current GPU memory usage by \n",
    "\t\t# tensors in bytes for a given device\n",
    "\t\t#torch.cuda.memory_allocated()\n",
    "\t\t# Returns the current GPU memory managed by the\n",
    "\t\t# caching allocator in bytes for a given device\n",
    "\t\t#torch.cuda.memory_cached()\n",
    "\n",
    "        # evaluate on validation set\n",
    "        \n",
    "       #two models are saved \n",
    "        if epoch == logger.best_epoch:\n",
    "            save_ckpt({'arch': model_name,\n",
    "                       'state_dict': model.state_dict(),\n",
    "                       'epoch' : epoch,\n",
    "                       'optimizer_state_dict': optimizer.state_dict()},\n",
    "                      model_name, is_best=True)\n",
    "        else:\n",
    "            save_ckpt({'arch': model_name,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer_state_dict': optimizer.state_dict()},\n",
    "                  model_name, is_best=False)\n",
    "\n",
    "        if epoch == logger.best_epoch:\n",
    "            torch.save({'arch': model_name,\n",
    "                       'state_dict': model.module.state_dict(), #add .module because of DataParallel for one GPU reading\n",
    "                        'epoch' : epoch,\n",
    "                       'optimizer_state_dict': optimizer.state_dict()},\n",
    "                      os.path.join('../results', model_name, 'one_gpu_best.tar'))\n",
    "        else :\n",
    "            torch.save({'arch': model_name,\n",
    "                       'state_dict': model.module.state_dict(), #add .module because of DataParallel \n",
    "                        'epoch' : epoch,\n",
    "                       'optimizer_state_dict': optimizer.state_dict()},\n",
    "                      os.path.join('../results', model_name, 'one_gpu.tar'))\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    \n",
    "    logger.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries=[]\n",
    "previous=-1\n",
    "all=True #to activate if you want all the query put in one class\n",
    "if (query is None):\n",
    "    all=True\n",
    "with open(os.path.join(data_path, 'info', 'queries_synsets_map.txt')) as f:\n",
    "        for line in f:\n",
    "            # Image path\n",
    "            if((line.split()[1] != previous) or all):\n",
    "                queries.append(int(line.split()[0]))\n",
    "                previous=line.split()[1]\n",
    "                #print(line.split()[0], \" \", line.split()[1])\n",
    "            elif ((len(queries)>=query) and not all):\n",
    "                print(\"over the class\", query, 'queries is', queries)\n",
    "                break\n",
    "query_synset_dic = {}\n",
    "with open(\"/home/betty/Pictures/webvision/info/queries_synsets_map.txt\") as f:\n",
    "    for line in f:\n",
    "       (key, val) = line.split()\n",
    "       if (int(val)<=int(query)):\n",
    "           query_synset_dic[int(key)] = val\n",
    "#print(\"We use \", query_synset_dic, \"queries as synset map\")\n",
    "# print(\"class weighted\", args.class_weighted )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We keep 294099  values out of 0 for validation\n",
      "flickr\n",
      "num class 5000\n",
      "the maximum class for flickr_images_resized is 5000 with 7710236 imgs\n",
      "google\n",
      "num class 5000\n",
      "the maximum class for google_images_resized is 5000 with 8312883 imgs\n",
      "Validation and training data loaded\n",
      "training from both, on 16023119\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = load_data(data_root=data_path,queries=queries,\n",
    "            query_synset_dic_=query_synset_dic, batch_size=batch_size,num_workers=num_workers,\n",
    "                in_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use [3] on 1 GPUs!\n",
      "Successfully load the saved model at /home/betty/webvision_train/results/resnet50/5000classes_onemonth/one_gpu_best.tar\n",
      "Start validation..\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc1_avg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-2c0744f5ec93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mclass_weighted_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m              )\n",
      "\u001b[0;32m<ipython-input-77-20209a3a69de>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(gpus, epochs, data_folder, batch_size, base_lr, model_name, weight_decay, num_workers, num_classes, print_freq, save_freq, load_path, class_weighted_, valid_loader, train_loader)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0madjust_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-0ba5652a6176>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(valid_loader, model, criterion, epoch, log, print_freq)\u001b[0m\n\u001b[1;32m     70\u001b[0m                   .format(top1_val=top1.val/float(labels.size(0)),\n\u001b[1;32m     71\u001b[0m                   \u001b[0;31m#top5_val=correct_5.item()/float(labels.size(0)),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                   top1=top1, top5=top5))\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;31m#cnf_matrix = confusion_matrix(cm_label, cm_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m#np.set_printoptions(precision=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc1_avg'"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "            data_folder = data_folder,\n",
    "            gpus=gpus,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            base_lr=lr,\n",
    "            model_name=arch,\n",
    "            weight_decay=weight_decay,\n",
    "            num_workers=num_workers,\n",
    "            print_freq=print_freq,\n",
    "            save_freq= save_freq,\n",
    "            load_path=load_path, \n",
    "            class_weighted_= False,\n",
    "            train_loader=train_loader,\n",
    "            valid_loader=valid_loader\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
